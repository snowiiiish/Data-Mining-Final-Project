import pandas as pd
import numpy as np
import re
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# ==================================================
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# ==================================================

reviews = pd.read_csv("reviews.csv")
salons = pd.read_csv("salons.csv")

# ==================================================
# 2. –û—á–∏—Å—Ç–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π
# ==================================================

# —Ä–µ–π—Ç–∏–Ω–≥
salons["rating"] = (
    salons["rating"]
    .astype(str)
    .str.replace(",", ".", regex=False)
    .astype(float)
)

# –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ ("1093 –æ—Ü–µ–Ω–∫–∏" -> 1093)
salons["total_reviews_count"] = (
    salons["total_reviews_count"]
    .astype(str)
    .str.extract(r"(\d+)")
    .astype(float)
    .fillna(0)
)

# ==================================================
# 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–π–æ–Ω–æ–≤ (–∫–ª—é—á–µ–≤–∞—è —á–∞—Å—Ç—å)
# ==================================================

def normalize_text(text: str) -> str:
    text = text.lower()
    text = text.replace("—Ä–∞–π–æ–Ω", "")
    text = re.sub(r"[^\w\s]", "", text)
    text = text.strip()

    # —É–±–∏—Ä–∞–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è
    for suffix in ["—Å–∫–∏–π", "—Å–∫–æ–º", "—Å–∫–æ–≥–æ", "—Å–∫–∞—è", "—Å–∫–æ–π", "—Å–∫–æ–º"]:
        if text.endswith(suffix):
            text = text.replace(suffix, "")
    return text


salons["district_normalized"] = salons["district"].apply(normalize_text)

# –∫–∞—Ä—Ç–∞: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π ‚Üí –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π
district_map = dict(
    zip(salons["district_normalized"], salons["district"])
)

# ==================================================
# 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–∑—ã–≤–æ–≤ (–Ω–µ–≥–∞—Ç–∏–≤ —à—Ç—Ä–∞—Ñ—É–µ—Ç—Å—è)
# ==================================================

def build_reviews(group):
    texts = []
    negative = 0

    for _, row in group.iterrows():
        if row["rating"] <= 2:
            texts.append(f"–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–∑—ã–≤: {row['text']}")
            negative += 1
        else:
            texts.append(f"–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π –æ—Ç–∑—ã–≤: {row['text']}")

    return " ".join(texts), negative


reviews_agg = (
    reviews
    .groupby("salon_id")
    .apply(
        lambda g: pd.Series(
            build_reviews(g),
            index=["reviews_text", "negative_reviews_count"]
        )
    )
    .reset_index()
)

# ==================================================
# 5. Merge
# ==================================================

data = salons.merge(reviews_agg, on="salon_id", how="left")
data["reviews_text"] = data["reviews_text"].fillna("")
data["negative_reviews_count"] = data["negative_reviews_count"].fillna(0)

# ==================================================
# 6. –¢–µ–∫—Å—Ç –¥–ª—è embedding
# ==================================================

data["full_text"] = (
    "–°–∞–ª–æ–Ω: " + data["name"] + ". "
    "–†–∞–π–æ–Ω: " + data["district"] + ". "
    "–ê–¥—Ä–µ—Å: " + data["address"] + ". "
    "–†–µ–π—Ç–∏–Ω–≥: " + data["rating"].astype(str) + ". "
    "–û—Ç–∑—ã–≤—ã: " + data["reviews_text"]
)

# ==================================================
# 7. Embedding –º–æ–¥–µ–ª—å
# ==================================================

model = SentenceTransformer("all-MiniLM-L6-v2")

salon_embeddings = model.encode(
    data["full_text"].tolist(),
    show_progress_bar=True
)

# ==================================================
# 8. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–π–æ–Ω–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
# ==================================================

def extract_district(query: str):
    q_norm = normalize_text(query)

    for d_norm, original in district_map.items():
        if d_norm and d_norm in q_norm:
            return original

    return None

# ==================================================
# 9. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
# ==================================================

def recommend_salon(
    query: str,
    top_k: int = 3,
    min_rating: float = 3.0,
    penalty_weight: float = 0.1
):
    # üîç —Ä–∞–π–æ–Ω –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
    detected_district = extract_district(query)

    filtered_data = data.copy()
    filtered_embeddings = salon_embeddings

    if detected_district:
        print(f"üìç –†–∞–π–æ–Ω –∏–∑ –∑–∞–ø—Ä–æ—Å–∞: {detected_district}")

        mask = (
            filtered_data["district"] == detected_district
        )
        filtered_data = filtered_data[mask]
        filtered_embeddings = salon_embeddings[mask.values]

        if filtered_data.empty:
            return "‚ùå –ù–µ—Ç —Å–∞–ª–æ–Ω–æ–≤ –≤ —ç—Ç–æ–º —Ä–∞–π–æ–Ω–µ"

    # ‚≠ê —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ä–µ–π—Ç–∏–Ω–≥—É
    mask_rating = filtered_data["rating"] >= min_rating
    filtered_data = filtered_data[mask_rating]
    filtered_embeddings = filtered_embeddings[mask_rating.values]

    if filtered_data.empty:
        return "‚ùå –ù–µ—Ç —Å–∞–ª–æ–Ω–æ–≤ —Å –ø–æ–¥—Ö–æ–¥—è—â–∏–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º"

    # üß† embedding –∑–∞–ø—Ä–æ—Å–∞
    query_emb = model.encode([query])

    similarities = cosine_similarity(
        query_emb,
        filtered_embeddings
    )[0]

    filtered_data = filtered_data.copy()
    filtered_data["base_score"] = similarities

    # üîª —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–≥–∞—Ç–∏–≤
    filtered_data["penalty"] = np.where(
        filtered_data["total_reviews_count"] > 0,
        (filtered_data["negative_reviews_count"] /
         filtered_data["total_reviews_count"]) * penalty_weight,
        0
    )

    filtered_data["final_score"] = (
        filtered_data["base_score"] - filtered_data["penalty"]
    )

    return (
        filtered_data
        .sort_values("final_score", ascending=False)
        .head(top_k)
        [["name", "district", "rating", "final_score"]]
    )

# ==================================================
# 10. –ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞
# ==================================================

if __name__ == "__main__":
    queries = [
        "–≤—ã–¥–∞–π –º–Ω–µ —Å–∞–ª–æ–Ω –≤ –±–æ—Å—Ç–∞–Ω–¥—ã–∫—Å–∫–∏–π —Ä–∞–π–æ–Ω",
        "–∏—â—É —Å–∞–ª–æ–Ω –≤ –±–æ—Å—Ç–∞–Ω–¥—ã–∫—Å–∫–æ–º —Ä–∞–π–æ–Ω–µ –¥–ª—è —Ä–µ—Å–Ω–∏—Ü",
        "–∞–∫–∫—É—Ä–∞—Ç–Ω–æ–µ –Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ —Ä–µ—Å–Ω–∏—Ü –≤ –∞–ª–º–∞–ª–∏–Ω—Å–∫–æ–º",
        "—Ö–æ—á—É —Ö–æ—Ä–æ—à–∏–π —Å–∞–ª–æ–Ω"
    ]

    for q in queries:
        print("\nüîç", q)
        print(recommend_salon(q))
